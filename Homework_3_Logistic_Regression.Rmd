---
title: "Homework 3"
subtitle: "4375 Machine Learning with Dr. Mazidi"
author: "Parker Whitehead"
date: "9/13/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

This homework runs logistic regression to predict the binary feature of whether or not a person was admitted to graduate school, based on a set of predictors: GRE score, TOEFL score, rating of undergrad university attended, SOP statement of purpose, LOR letter or recommendation, Undergrad GPA, Research experience (binary).

The data set was downloaded from Kaggle: https://www.kaggle.com/mohansacharya/graduate-admissions

The data is available in Piazza. 

## Step 1 Load the data

* Load the data
* Examine the first few rows with head()

```{r}
Admission <- read.csv("C:\\Users\\Dapper\\Desktop\\Admission_Predict.csv")
head(Admission)
```

## Step 2 Data Wrangling

Perform the following steps:

* Make Research a factor
* Get rid of the Serial No column
* Make a new column that is binary factor based on if Chance.of.Admit > 0.5. Hint: See p. 40 in the book. 
* Output column names with names() function
* Output a summary of the data
* Is the data set unbalanced? Why or why not?

 Your commentary here:
 The data set is somewhat unbalanced in that 365/400 students have above .5 odds of being accepted.

```{r}
Admission$Research <- factor(Admission$Research)
Admission$Serial.No. <- NULL
Admission$Admit <- FALSE
Admission$Admit[Admission$Chance.of.Admit>.5] <- TRUE
Admission$Admit <- factor(Admission$Admit, labels=c(".5<",".5>="))
names(Admission)
```

```{r}
summary(Admission)
```

## Step 3 Data Visualization

* Create a side-by-side graph with Admit on the x axis of both graphs, GRE score on the y axis of one graph and TOEFL score on the y axis of the other graph; save/restore the original graph parameters
* Comment on the graphs and what they are telling you about whether GRE and TOEFL are good predictors
* You will get a lot of warnings, you can suppress them with disabling warnings as shown below:

```
{r,warning=FALSE}
```

Your commentary here:
My first impression from the graphs were how few data points fell under .5< for Admit. However, despite the small data pool for that value, it is very clear that there is a positive correlation for Admit as a predictor for both gre and toefl. I believe them both to be very good predictors.
```{r,warning=FALSE}
par(mfrow=c(1,2))
plot(GRE.Score~Admit, data=Admission, varwidth=TRUE)
plot(TOEFL.Score~Admit, data=Admission, varwidth=TRUE)
```


## Step 4 Divide train/test

* Divide into 75/25 train/test, using seed 1234

```{r}
# your code here
set.seed(1234)
i = sample(1:nrow(Admission),nrow(Admission)*.75,replace=FALSE)
train <- Admission[i,]
test <- Admission[-i,]
```

## Step 5 Build a Model with all predictors 

* Build a model, predicting Admit from all predictors
* Output a summary of the model
* Did you get an error? Why? Hint: see p. 120 Warning

Your commentary here: 
I did indeed get an error. This is because we are including chance.of.admit in the model, which predicts Admit with 100% accuracy since Admit is simply a factorization of chance.of.admit.
```{r}
glm1 <- glm(Admit~., data=train, family=binomial)
summary(glm1)
```

## Step 6 Build a Model with all predictors except Chance.of.Admit

* Build another model, predicting Admit from all predictors *except* Chance.of.Admit
* Output a summary of the model
* Did you get an error? Why or why not?
I did not get an error, as removing the 1:1 predictor (chance.of.admit) from the data caused R to not warn me of a non-converging algorithm. 
```{r}
# your code here
train2 <-train[c(1:7,9)]
glm2 <- glm(Admit~., data=train2, family=binomial)
summary(glm2)
```

## Step 7 Predict probabilities

* Predict the probabilities using type="response"
* Examine a few probabilities and the corresponding Chance.of.Admit values
* Run cor() on the predicted probs and the Chance.of.Admit, and output the correlation
* What do you conclude from this correlation. 

Your commentary here:
Due to the very high percentage of students who have a value of .5 or higher on chance.of.admit, when reduced to a binomial factor, it can be very difficult to accurately predict the exact decimal values. However, despite this. The model still does a fair job. Not as good as we would like, but not bad, per say. 
```{r}
# your code here
probs1 <- predict(glm2, newdata=test, type="response")
summary(probs1)
print(paste("Estimated values: ", probs1[c(1:5)], "Actual Value: ", test[c(1:5),8]))
print(paste("correlation: ", cor(probs1,test$Chance.of.Admit)))
```

## Step 8 Make binary predictions, print table and accuracy

* Run predict() again, this time making binary predictions
* Output a table comparing the predictions and the binary Admit column
* Calculate and output accuracy
* Was the model able to generalize well to new data?

Your commentary here:
The model was excellent in predicting the factor value "Admit" of the test data. Now that the binomial glm was being compared to/predicted as a binomial, the prediction was much more accurate.
```{r}
probs2 <- predict(glm2, newdata=test, type="response")
pred2 <- ifelse(probs2>.5,".5>=",".5<")
table(pred2, test$Admit)
acc <- mean(pred2==test$Admit)
print(paste("Accuracy: ",acc))
```

## Step 9 Output ROCR and AUC

* Output a ROCR graph
* Extract and output the AUC metric

```{r}
library(ROCR)
p <- predict(glm2, newdata=test, type="response")
pr <- prediction(p,test$Admit)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
print(paste("AUC: ",auc))
```


## Step 10

* Make two more graphs and comment on what you learned from each graph:
  * Admit on x axis, SOP on y axis
  * Research on x axis, SOP on y axis
  
Your commentary here:
Both Admit and Research are good indicators for SOP, and follow a very similar positive trend.

```{r}
plot(SOP~Admit, data=Admission)
```

```{r}
plot(SOP~Research, data=Admission)
```

